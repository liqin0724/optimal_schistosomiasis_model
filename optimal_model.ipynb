{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c31bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import shap\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "shap.initjs()\n",
    "import pandas as pd\n",
    "df = pd.read_excel('mydata.xlsx')\n",
    "df.sort_values(by=['id', 'year'], ascending=[True, True], inplace=True, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731918fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[~df.year.isin([2002, 2003, 2004, 2005])].reset_index().rename(columns={'index': 'original_index'})\n",
    "for i in range(len(df_new)):\n",
    "    df_new.HE.iloc[i] = df.HE.iloc[df_new.original_index.iloc[i]-2]\n",
    "    df_new.EMSC.iloc[i] = df.EMSC.iloc[df_new.original_index.iloc[i]-4]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e23d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new.iloc[:,6:]\n",
    "y = df_new['rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1ea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    " \n",
    "# 参数集定义\n",
    "param_grid = {\n",
    "            'max_depth': [2, 3, 4, 5, 6, 7, 8], #  基本学习器的深度： 基本学习器的数量： 要拟合的弱学习器数量，该值越大，模型越复杂，越容易过拟合树的最大深度，该值越大，模型越复杂，越容易拟合训练数据，越容易过拟合;树生长停止条件之一\n",
    "            'n_estimators': [30, 50, 100, 300, 500, 1000,2000], # 基本学习器的数量： 要拟合的弱学习器数量，该值越大，模型越复杂，越容易过拟合\n",
    "            'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.01, 0.02, 0.03, 0.05, 0.5],# 学习率：每个基模型的惩罚项，降低单个模型的影响，为了防止过拟合，该值越接近1越容易或拟合，越接近0精度越低\n",
    "            \"gamma\":[0.0, 0.1, 0.2, 0.3, 0.4],#损失减少阈值： 在树的叶节点上进一步划分所需的最小损失减少，在模型训练过程中，只有损失下降的值超过该值，才会继续分裂节点，该值越小模型越复杂，越容易过拟合,树生长停止条件之一\n",
    "            \"reg_alpha\":[0.0001,0.001, 0.01, 0.1, 1, 100],# L1正则化：L1正则化用于对叶子的个数进行惩罚,用于防止过拟合\n",
    "            \"reg_lambda\":[0.0001,0.001, 0.01, 0.1, 1, 100],# L2正则化:L2正则化用于对叶子节点的得分进行惩罚，L1和L2正则化项共同惩罚树的复杂度,值越小模型的鲁棒性越高\n",
    "            \"min_child_weight\": [2,3,4,5,6,7,8],\n",
    "            \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9],\n",
    "            \"subsample\":[0.6, 0.7, 0.8, 0.9]}\n",
    "# 随机搜索并打印最佳参数\n",
    "gsearch1 = RandomizedSearchCV(XGBRegressor(), param_grid, cv=4)\n",
    "\n",
    "gsearch1.fit(X, y)\n",
    "\n",
    "print(\"best_score_:\",gsearch1.best_params_,gsearch1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7fa4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = xgboost.XGBRegressor(**gsearch1.best_params_)\n",
    "model = best_model.fit(X, y)\n",
    "mean_squared_error(y,model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = xgboost.XGBRegressor()\n",
    "model = best_model.fit(X, y)\n",
    "mean_squared_error(y,model.predict(X))\n",
    "from xgboost import plot_importance\n",
    "plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a810ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用SHAP解释模型预测\n",
    "model = best_model.fit(X, y)\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X)\n",
    "shap_values\n",
    "import ipywidgets as widgets\n",
    "import pyecharts.options as opts\n",
    "from pyecharts.charts import Pie\n",
    "# 选择样本的id和year\n",
    "sample_id, year = widgets.IntSlider(value=1,min=1,max=8,step=1,description='ID:',disabled=False,continuous_update=False,orientation='horizontal',readout=True,readout_format='d'),\\\n",
    "                  widgets.IntSlider(value=2006,min=2006,max=2021,step=1,description='YEAR:',disabled=False,continuous_update=False,orientation='horizontal',readout=True,readout_format='d')\n",
    "sample_id.style.handle_color = 'lightblue'\n",
    "year.style.handle_color = 'lightgreen'\n",
    "display(sample_id, year)\n",
    "# 根据选择的id和year找到样本的index\n",
    "sample_index = df_new[(df_new.id==sample_id.value) & (df_new.year==year.value)].index[0]\n",
    "# 选择的样本的解释：以瀑布图形式可视化\n",
    "shap.plots.waterfall(shap_values[sample_index])\n",
    "# 选择的样本的解释：以力图形式可视化\n",
    "shap.plots.force(shap_values[sample_index])\n",
    "# 选择的样本的解释：以环形图形式可视化\n",
    "x_data = list(df_new)[6:]\n",
    "y_data = list(map(abs, shap_values[sample_index].values))\n",
    "y_data = [i*10 for i in y_data]\n",
    "print(y_data)\n",
    "data_pair = [list(z) for z in zip(x_data, y_data)]\n",
    "data_pair.sort(key=lambda x: x[1])\n",
    "pie = (\n",
    "    Pie(init_opts=opts.InitOpts())\n",
    "    .add(\n",
    "        series_name=f\"Shap Value of Sample{sample_index} (id={sample_id.value}, year={year.value})\",\n",
    "        data_pair=data_pair,\n",
    "        rosetype=\"radius\",\n",
    "        radius=[\"50%\", \"70%\"],\n",
    "        label_opts=opts.LabelOpts(is_show=False, position=\"center\"),\n",
    "    )\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(\n",
    "            title=\"Shap Value可视化\",\n",
    "            pos_left=\"center\",\n",
    "            pos_top=\"20\",\n",
    "            title_textstyle_opts=opts.TextStyleOpts(color=\"#2a4d69\"),\n",
    "        ),\n",
    "        legend_opts=opts.LegendOpts(type_=\"scroll\", pos_left=\"80%\", orient=\"vertical\"),\n",
    "    )\n",
    "    .set_series_opts(\n",
    "        tooltip_opts=opts.TooltipOpts(\n",
    "            trigger=\"item\", formatter=\"{a} <br/>{b}: {c}/10 ({d}%)\"\n",
    "        ),\n",
    "        label_opts=opts.LabelOpts(),\n",
    "    )\n",
    ")\n",
    "pie.render_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24babfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = df_new.groupby('id').mean().iloc[:,5:]\n",
    "df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_hill = pd.DataFrame(df_new.groupby('id').sum().iloc[:,5:].loc[[2,3,7,8]].sum()/48).T\n",
    "combination_hill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68654966",
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_lake = pd.DataFrame(df_new.groupby('id').sum().iloc[:,5:].loc[[1,4,5,6,9,10,11]].sum()/48).T\n",
    "combination_lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f4cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择的样本某年的解释：以环形图形式可视化\n",
    "\n",
    "x_data = list(df_new)[6:]\n",
    "x_data_mean = [i+\" Mean\" for i in x_data]\n",
    "y_data = list(map(abs, combination_1_4_5_6.values.tolist()[0]))\n",
    "y_data = [i for i in y_data]\n",
    "\n",
    "data_pair = [list(z) for z in zip(x_data_mean, y_data)]\n",
    "data_pair.sort(key=lambda x: x[1])\n",
    "pie = (\n",
    "    Pie(init_opts=opts.InitOpts())\n",
    "    .add(\n",
    "        series_name=f\"Feature Mean of id=1, 4, 5, 6\",\n",
    "        data_pair=data_pair,\n",
    "        rosetype=\"radius\",\n",
    "        radius=[\"50%\", \"70%\"],\n",
    "        label_opts=opts.LabelOpts(is_show=False, position=\"center\"),\n",
    "    )\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(\n",
    "            title=f\"湖沼型流行区干预优先级可视化\",\n",
    "            pos_left=\"center\",\n",
    "            pos_top=\"20\",\n",
    "            title_textstyle_opts=opts.TextStyleOpts(color=\"#2a4d69\"),\n",
    "        ),\n",
    "        legend_opts=opts.LegendOpts(type_=\"scroll\", pos_left=\"80%\", orient=\"vertical\"),\n",
    "    )\n",
    "    .set_series_opts(\n",
    "        tooltip_opts=opts.TooltipOpts(\n",
    "            trigger=\"item\", formatter=\"{a} <br/>{b}: {c} ({d}%)\"\n",
    "        ),\n",
    "        label_opts=opts.LabelOpts(),\n",
    "    )\n",
    ")\n",
    "pie.render_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f9031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择的样本某年的解释：以环形图形式可视化\n",
    "\n",
    "x_data = list(df_new)[6:]\n",
    "x_data_mean = [i+\" Mean\" for i in x_data]\n",
    "y_data = list(map(abs, combination_2_3_7_8.values.tolist()[0]))\n",
    "y_data = [i for i in y_data]\n",
    "\n",
    "data_pair = [list(z) for z in zip(x_data_mean, y_data)]\n",
    "data_pair.sort(key=lambda x: x[1])\n",
    "pie = (\n",
    "    Pie(init_opts=opts.InitOpts())\n",
    "    .add(\n",
    "        series_name=f\"Feature Mean of id=2, 3, 7, 8\",\n",
    "        data_pair=data_pair,\n",
    "        rosetype=\"radius\",\n",
    "        radius=[\"50%\", \"70%\"],\n",
    "        label_opts=opts.LabelOpts(is_show=False, position=\"center\"),\n",
    "    )\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(\n",
    "            title=f\"山丘型流行区干预优先级可视化\",\n",
    "            pos_left=\"center\",\n",
    "            pos_top=\"20\",\n",
    "            title_textstyle_opts=opts.TextStyleOpts(color=\"#2a4d69\"),\n",
    "        ),\n",
    "        legend_opts=opts.LegendOpts(type_=\"scroll\", pos_left=\"80%\", orient=\"vertical\"),\n",
    "    )\n",
    "    .set_series_opts(\n",
    "        tooltip_opts=opts.TooltipOpts(\n",
    "            trigger=\"item\", formatter=\"{a} <br/>{b}: {c} ({d}%)\"\n",
    "        ),\n",
    "        label_opts=opts.LabelOpts(),\n",
    "    )\n",
    ")\n",
    "pie.render_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8251ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择的样本某年的解释：以环形图形式可视化\n",
    "\n",
    "x_data = list(df_new)[6:]\n",
    "x_data_mean = [i+\" Mean\" for i in x_data]\n",
    "y_data = list(map(abs, df_mean.loc[[sample_id_for_mean.value]].values.tolist()[0]))\n",
    "y_data = [i for i in y_data]\n",
    "\n",
    "data_pair = [list(z) for z in zip(x_data_mean, y_data)]\n",
    "data_pair.sort(key=lambda x: x[1])\n",
    "pie = (\n",
    "    Pie(init_opts=opts.InitOpts())\n",
    "    .add(\n",
    "        series_name=f\"Feature Mean of id={sample_id_for_mean.value}\",\n",
    "        data_pair=data_pair,\n",
    "        rosetype=\"radius\",\n",
    "        radius=[\"60%\", \"80%\"],\n",
    "        label_opts=opts.LabelOpts(is_show=False, position=\"center\"),\n",
    "    )\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(\n",
    "            #title=f\"id为{sample_id_for_mean.value}的特征均值可视化\",\n",
    "            pos_left=\"center\",\n",
    "            pos_top=\"20\",\n",
    "            title_textstyle_opts=opts.TextStyleOpts(color=\"#2a4d69\"),\n",
    "        ),\n",
    "        legend_opts=opts.LegendOpts(type_=\"scroll\", pos_left=\"90%\", orient=\"vertical\"),\n",
    "    )\n",
    "    .set_series_opts(\n",
    "        tooltip_opts=opts.TooltipOpts(\n",
    "            trigger=\"item\", formatter=\"{a} <br/>{b}: {c} ({d}%)\"\n",
    "        ),\n",
    "        label_opts=opts.LabelOpts(),\n",
    "    )\n",
    ")\n",
    "pie.render_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad2b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有样本的解释：以力图形式可视化\n",
    "shap.force_plot(explainer.expected_value, shap_values.values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac68fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取每个特征的SHAP值的绝对值的平均值作为该特征的重要性\n",
    "shap.summary_plot(shap_values, X, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374400d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征依赖\n",
    "# 横轴：Treat effects，纵轴：MSC\n",
    "shap.dependence_plot(\"Treat\", shap_values.values, X, interaction_index='MSC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea4cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "feature_list = list(df_new)[6:]\n",
    "combinations_dict = {}\n",
    "for n in range(3,10):\n",
    "    combinations_dict[n] = []\n",
    "    for i in combinations(feature_list, n):\n",
    "        combinations_dict[n].append(list(i))\n",
    "combinations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b672e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "mse_dict = {}\n",
    "r2_dict = {}\n",
    "rmse_dict = {}\n",
    "mae_dict = {}\n",
    "for n in combinations_dict.keys():\n",
    "    mse_dict[n] = []\n",
    "    r2_dict[n] = []\n",
    "    rmse_dict[n] = []\n",
    "    mae_dict[n] = []\n",
    "    for i in combinations_dict[n]:\n",
    "        X_compare = df_new[i]\n",
    "        model_compare = xgboost.XGBRegressor()\n",
    "        model_compare = model_compare.fit(X_compare, y)\n",
    "        y_predict = model_compare.predict(X_compare)\n",
    "        mse = mean_squared_error(y, y_predict)\n",
    "        r2 = r2_score(y, y_predict)\n",
    "        rmse = mean_squared_error(y, y_predict, squared=False)\n",
    "        mae = mean_absolute_error(y, y_predict)\n",
    "        mse_dict[n].append(mse)\n",
    "        r2_dict[n].append(r2)\n",
    "        rmse_dict[n].append(rmse)\n",
    "        mae_dict[n].append(mae)\n",
    "# mse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafb1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_list = []\n",
    "for i in r2_dict.keys():\n",
    "     for j in range(len(r2_dict[i])):\n",
    "         r2_list.append([r2_dict[i][j], combinations_dict[i][j]])\n",
    "mse_list = []\n",
    "for i in mse_dict.keys():\n",
    "     for j in range(len(mse_dict[i])):\n",
    "         mse_list.append([mse_dict[i][j], combinations_dict[i][j]])\n",
    "rmse_list = []\n",
    "for i in rmse_dict.keys():\n",
    "     for j in range(len(rmse_dict[i])):\n",
    "         rmse_list.append([rmse_dict[i][j], combinations_dict[i][j]])\n",
    "mae_list = []\n",
    "for i in mae_dict.keys():\n",
    "     for j in range(len(mae_dict[i])):\n",
    "         mae_list.append([mae_dict[i][j], combinations_dict[i][j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42991f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_RS = abs(shap_values.values[:, -1]).tolist()\n",
    "shap_normal = np.average(abs(shap_values.values[:, :-1]), axis=1).tolist()\n",
    "RS = df_new['RS'].tolist()\n",
    "benefit = [i*j for i, j in zip(shap_RS, RS)]\n",
    "loss = [i*j for i, j in zip(shap_normal, RS)]\n",
    "RS_related = pd.DataFrame({'id': df_new['id'], 'year': df_new['year'], 'RS cost': RS, 'shap_RS': shap_RS, \n",
    "                            'shap_normal': shap_normal, 'benefit': benefit, 'loss': loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b92d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_draw = {'cost': cost,\n",
    "             'R2': pre_y,\n",
    "             'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c505a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
